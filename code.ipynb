{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_collab():\n",
    "    %pip install torchmetrics\n",
    "    \n",
    "    # Download the dataset\n",
    "    !wget https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/BSDS300-images.tgz\n",
    "    !tar -xvzf BSDS300-images.tgz\n",
    "    !rm BSDS300-images.tgz\n",
    "    \n",
    "    COLLAB_ININITALIZED = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outside Collab\n"
     ]
    }
   ],
   "source": [
    "# check if we are running on colab\n",
    "try:\n",
    "    import google.colab\n",
    "    print(\"In Collab\")\n",
    "    if COLLAB_INITIALIZED == True:\n",
    "        print(\"Colab Already Initialized\")\n",
    "    else:\n",
    "        print(\"Initializing Colab\")\n",
    "        setup_collab()\n",
    "        print(\"Colab Initialized\")\n",
    "except:\n",
    "    print(\"Outside Collab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import tqdm  # for nice progress bars\n",
    "from matplotlib import pyplot as plt\n",
    "from torchmetrics.functional import peak_signal_noise_ratio, structural_similarity_index_measure\n",
    "\n",
    "from torch import nn\n",
    "from unet import Unet\n",
    "\n",
    "from datasets import NoisyCleantDataset, NoisyNoisyDataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"./BSDS300\"\n",
    "\n",
    "train_set_dir = f\"{dataset_dir}/images/train\"\n",
    "train_img_files = [f\"{train_set_dir}/{filename}\" for filename in os.listdir(train_set_dir)]\n",
    "# use this to train with fewer data\n",
    "# train_img_files = random.sample(train_img_files, 50)\n",
    "\n",
    "test_set_dir = f\"{dataset_dir}/images/test\"\n",
    "test_img_files = [f\"{test_set_dir}/{filename}\" for filename in os.listdir(test_set_dir)]\n",
    "val_img_files = test_img_files[:50]\n",
    "test_img_files = test_img_files[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_var = 0.015  # more noise makes denoising harder; we suggest you keep this value but you can also experiment with more or less noise\n",
    "train_chunk_size = 128  # depends on your hardware; larger chunks require more memory during gradient computation; we recommend 128\n",
    "\n",
    "train_set_supervised = NoisyCleantDataset(img_files=train_img_files, noise_var=noise_var, chunk_size=train_chunk_size)\n",
    "train_set_sel_supervised = NoisyNoisyDataset(img_files=train_img_files, noise_var=noise_var, chunk_size=train_chunk_size)\n",
    "\n",
    "# for validation and testing, we do not have to split the images into chunks because we do not have to compute gradients\n",
    "# the images have shape (321, 481) or (481, 321) so we crop them to (321, 321) to facilitate data loading\n",
    "val_set = NoisyCleantDataset(img_files=val_img_files, noise_var=noise_var, chunk_size=321)\n",
    "test_set = NoisyCleantDataset(img_files=test_img_files, noise_var=noise_var, chunk_size=321)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,  train_loader, val_loader, optimizer, loss_fn_main, extra_loss_functions_validation, max_epochs, check_val_every_epochs, limit_train_length=None):\n",
    "    best_validation_loss = float(\"inf\")\n",
    "    best_model_parameters = None\n",
    "    history_main_validation_losses = []\n",
    "    history_additional_validation_losses = {\n",
    "        key: [] for key in extra_loss_functions_validation.keys()\n",
    "    }\n",
    "\n",
    "    no_of_training_examples = 0\n",
    "\n",
    "    print(\"Starting training\")\n",
    "    for e in range(max_epochs):\n",
    "        # Train one epoch\n",
    "        for imgs_noisy, imgs_clean in tqdm.tqdm(train_loader, desc=\"Training\"):\n",
    "\n",
    "            # limit train length (when optional argument is set)\n",
    "            if limit_train_length is not None:\n",
    "                batch_size = imgs_noisy.shape[0]\n",
    "                no_of_training_examples_reamaining = limit_train_length - no_of_training_examples\n",
    "                if no_of_training_examples_reamaining <= 0:\n",
    "                    print(\"Preemptively stopping training because limit_train_length was reached\")\n",
    "                    break\n",
    "                elif no_of_training_examples_reamaining < batch_size:\n",
    "                    imgs_noisy = imgs_noisy[:no_of_training_examples_reamaining]\n",
    "                    imgs_clean = imgs_clean[:no_of_training_examples_reamaining]\n",
    "                    no_of_training_examples += no_of_training_examples_reamaining\n",
    "                else:\n",
    "                    no_of_training_examples += batch_size\n",
    "            \n",
    "            # Proper training\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            imgs_noisy = imgs_noisy.to(device)\n",
    "            imgs_clean = imgs_clean.to(device)\n",
    "        \n",
    "            out = model(imgs_noisy)  # forward pass\n",
    "            imgs_denoised = imgs_noisy - out            \n",
    "            loss = loss_fn_main(imgs_denoised, imgs_clean)\n",
    "\n",
    "            # run gradient update\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # validate model\n",
    "        if (e + 1) % check_val_every_epochs == 0:\n",
    "            loss_main_loss_function_averaged, losses_additional_functions_averaged = validate_model(model, val_loader, loss_fn_main, extra_loss_functions_validation)\n",
    "            # add losses to history\n",
    "            history_main_validation_losses.append(loss_main_loss_function_averaged)\n",
    "            for key, loss in losses_additional_functions_averaged.items():\n",
    "                history_additional_validation_losses[key].append(loss)\n",
    "\n",
    "            print(f\"Validation loss (main function) after epoch {e}: {loss_main_loss_function_averaged}\")\n",
    "            print(f\"Validation losses (additional functions) after epoch {e}: {losses_additional_functions_averaged}\")\n",
    "            \n",
    "            # save best model parameters\n",
    "            if loss_main_loss_function_averaged < best_validation_loss:\n",
    "                best_validation_loss = loss_main_loss_function_averaged\n",
    "                best_model_parameters = model.state_dict()\n",
    "            \n",
    "            # save model checkpoint\n",
    "            print(\"Checkpoint saved\")\n",
    "            torch.save({\n",
    "                \"epoch\": e,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"best_model_state_dict\": best_model_parameters,\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"history_main_validation_loss\": history_main_validation_losses,\n",
    "                \"history_additional_validation_losses\": history_additional_validation_losses,\n",
    "            }, f\"checkpoint_{model.name}.pth\")\n",
    "\n",
    "    print(\"Training finished\")\n",
    "\n",
    "    # one final evaluation at the end of training\n",
    "    loss_main_loss_function_averaged, losses_additional_functions_averaged = validate_model(model, val_loader, loss_fn_main, extra_loss_functions_validation)\n",
    "    # add losses to history\n",
    "    history_main_validation_losses.append(loss_main_loss_function_averaged)\n",
    "    for key, loss in losses_additional_functions_averaged.items():\n",
    "        history_additional_validation_losses[key].append(loss)\n",
    "    \n",
    "    print(f\"Validation loss (main function) after training: {loss_main_loss_function_averaged}\")\n",
    "    print(f\"Validation losses (additional functions) after training: {losses_additional_functions_averaged}\")\n",
    "\n",
    "    # save best model parameters\n",
    "    if loss_main_loss_function_averaged < best_validation_loss:\n",
    "        best_validation_loss = loss_main_loss_function_averaged\n",
    "        best_model_parameters = model.state_dict()\n",
    "\n",
    "    # save model checkpoint\n",
    "    print(\"Checkpoint saved\")\n",
    "    torch.save({\n",
    "        \"epoch\": max_epochs,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"best_model_state_dict\": best_model_parameters,\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"history_main_validation_loss\": history_main_validation_losses,\n",
    "        \"history_additional_validation_losses\": history_additional_validation_losses,\n",
    "    }, f\"checkpoint_{model.name}.pth\")\n",
    "\n",
    "    # load best model parameters\n",
    "    model.load_state_dict(best_model_parameters)\n",
    "\n",
    "def validate_model(model, val_loader, main_loss_function, additional_loss_functions):\n",
    "    losses_main_loss_function = []\n",
    "    losses_additional_validation_functions  = {\n",
    "        key: [] for key in additional_loss_functions.keys()\n",
    "    }\n",
    "    # disable gradient computation for validation\n",
    "    with torch.no_grad():\n",
    "        for imgs_noisy, imgs_clean in tqdm.tqdm(val_loader, desc=\"Validation\"):\n",
    "            imgs_noisy = imgs_noisy.to(device)\n",
    "            imgs_clean = imgs_clean.to(device)\n",
    "    \n",
    "            out = model(imgs_noisy)  # forward pass\n",
    "            imgs_denoised = imgs_noisy - out\n",
    "            \n",
    "            # generate loss for main loss function\n",
    "            losses_main_loss_function.append(main_loss_function(imgs_denoised, imgs_clean).item())\n",
    "            \n",
    "            # generate all losses\n",
    "            for key, loss_fn in additional_loss_functions.items():\n",
    "                losses_additional_validation_functions[key].append(loss_fn(imgs_denoised, imgs_clean).item())\n",
    "\n",
    "    # compute average losses\n",
    "    loss_main_loss_function_averaged = sum(losses_main_loss_function) / len(losses_main_loss_function)\n",
    "    losses_additional_functions_averaged = {}\n",
    "    for key, loss_list in losses_additional_validation_functions.items():\n",
    "        losses_additional_functions_averaged[key] = sum(loss_list) / len(loss_list)\n",
    "    \n",
    "    return loss_main_loss_function_averaged, losses_additional_functions_averaged\n",
    "\n",
    "\n",
    "\n",
    "def test_model(model, test_loader, loss_functions):\n",
    "    losses = {\n",
    "        key: [] for key in loss_functions.keys()\n",
    "    }\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs_noisy, imgs_clean in tqdm.tqdm(test_loader, desc=\"Test\"):\n",
    "            imgs_noisy = imgs_noisy.to(device)\n",
    "            imgs_clean = imgs_clean.to(device)\n",
    "\n",
    "            out = model(imgs_noisy)  # forward pass\n",
    "            imgs_denoised = imgs_noisy - out\n",
    "\n",
    "            # generate all losses\n",
    "            for key, loss_fn in loss_functions.items():\n",
    "                losses[key].append(loss_fn(imgs_denoised, imgs_clean).item())\n",
    "    \n",
    "    # compute average losses\n",
    "    for key, loss_list in losses.items():\n",
    "        losses[key] = sum(loss_list) / len(loss_list)\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_training_curves(checkpoint_path):\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    history_main_validation_losses = checkpoint[\"history_main_validation_loss\"]\n",
    "    history_additional_validation_losses = checkpoint[\"history_additional_validation_losses\"]\n",
    "\n",
    "    no_of_losses_tested = len(history_additional_validation_losses.keys()) + 1\n",
    "    max_plots_per_row = 3\n",
    "    no_of_rows = no_of_losses_tested // max_plots_per_row + (1 if no_of_losses_tested % max_plots_per_row != 0 else 0)\n",
    "    fig, ax = plt.subplots(no_of_rows, max_plots_per_row, figsize=(15, 5 * no_of_rows))\n",
    "    ax = ax.flatten()\n",
    "    ax[0].plot(history_main_validation_losses)\n",
    "    ax[0].set_title(\"Main loss function\")\n",
    "    ax[0].set_xlabel(\"Epoch\")\n",
    "    ax[0].set_ylabel(\"Loss\")\n",
    "    ax[0].grid()\n",
    "    for i, (key, loss_list) in enumerate(history_additional_validation_losses.items()):\n",
    "        ax[i + 1].plot(loss_list)\n",
    "        ax[i + 1].set_title(key)\n",
    "        ax[i + 1].set_xlabel(\"Epoch\")\n",
    "        ax[i + 1].set_ylabel(\"Loss\")\n",
    "        ax[i + 1].grid()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more pooling layers and convolutional kernels increase the complexity of the U-Net (see lecture notes)\n",
    "num_pool_layers = 4\n",
    "chans = 64\n",
    "\n",
    "# check if cuda is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 32 if device == \"cuda\" else 4  # depends on your hardware\n",
    "\n",
    "train_loader_supervised = DataLoader(train_set_supervised, batch_size=batch_size, shuffle=True)\n",
    "train_loader_sel_supervised = DataLoader(train_set_sel_supervised, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# define loss function\n",
    "mse = torch.nn.MSELoss()  # use the mean squared error loss function\n",
    "psnr =  peak_signal_noise_ratio # peak signal-to-noise ratio\n",
    "ssim = structural_similarity_index_measure # structural similarity index measure\n",
    "\n",
    "learning_rate = 1e-3\n",
    "epochs = 50\n",
    "check_val_every_epochs = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train supervised model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_supervised = Unet(\n",
    "    in_chans=1,  # 1 input channel as we use grayscale images as input\n",
    "    out_chans=1,  # 1 output channel as the model returns grayscale images\n",
    "    num_pool_layers=num_pool_layers,\n",
    "    chans=chans,\n",
    "    name=\"Unet_supervised\",\n",
    ")\n",
    "model_supervised = model_supervised.to(device)\n",
    "optimizer_supervised = torch.optim.Adam(model_supervised.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 46/300 [03:17<18:12,  4.30s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_model(\n\u001b[1;32m      2\u001b[0m     model\u001b[39m=\u001b[39;49mmodel_supervised,\n\u001b[1;32m      3\u001b[0m     optimizer\u001b[39m=\u001b[39;49moptimizer_supervised,\n\u001b[1;32m      4\u001b[0m     train_loader\u001b[39m=\u001b[39;49mtrain_loader_supervised,\n\u001b[1;32m      5\u001b[0m     val_loader\u001b[39m=\u001b[39;49mval_loader,\n\u001b[1;32m      6\u001b[0m     loss_fn_main\u001b[39m=\u001b[39;49mmse,\n\u001b[1;32m      7\u001b[0m     extra_loss_functions_validation\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mPSNR\u001b[39;49m\u001b[39m\"\u001b[39;49m: psnr, \u001b[39m\"\u001b[39;49m\u001b[39mSSIM\u001b[39;49m\u001b[39m\"\u001b[39;49m: ssim},\n\u001b[1;32m      8\u001b[0m     max_epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m      9\u001b[0m     check_val_every_epochs\u001b[39m=\u001b[39;49mcheck_val_every_epochs,\n\u001b[1;32m     10\u001b[0m     limit_train_length\u001b[39m=\u001b[39;49m\u001b[39m300\u001b[39;49m\n\u001b[1;32m     11\u001b[0m )\n",
      "Cell \u001b[0;32mIn[6], line 40\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, optimizer, loss_fn_main, extra_loss_functions_validation, max_epochs, check_val_every_epochs, limit_train_length)\u001b[0m\n\u001b[1;32m     37\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn_main(imgs_denoised, imgs_clean)\n\u001b[1;32m     39\u001b[0m     \u001b[39m# run gradient update\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     41\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     43\u001b[0m \u001b[39m# validate model\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/machine_learning/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/machine_learning/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    model=model_supervised,\n",
    "    optimizer=optimizer_supervised,\n",
    "    train_loader=train_loader_supervised,\n",
    "    val_loader=val_loader,\n",
    "    loss_fn_main=mse,\n",
    "    extra_loss_functions_validation={\"PSNR\": psnr, \"SSIM\": ssim},\n",
    "    max_epochs=epochs,\n",
    "    check_val_every_epochs=check_val_every_epochs,\n",
    "    limit_train_length=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./checkpoint_Unet_supervised.pth\"\n",
    "print_training_curves(model_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train self supervised model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_self_supervised = Unet(\n",
    "    in_chans=1,  # 1 input channel as we use grayscale images as input\n",
    "    out_chans=1,  # 1 output channel as the model returns grayscale images\n",
    "    num_pool_layers=num_pool_layers,\n",
    "    chans=chans,\n",
    "    name=\"Unet_self_supervised\",\n",
    ")\n",
    "model_self_supervised = model_self_supervised.to(device)\n",
    "optimizer_self_supervised = torch.optim.Adam(model_self_supervised.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(\n",
    "    model=model_self_supervised,\n",
    "    optimizer=optimizer_self_supervised,\n",
    "    train_loader=train_loader_sel_supervised,\n",
    "    val_loader=val_loader,\n",
    "    loss_fn_main=mse,\n",
    "    extra_loss_functions_validation={\"PSNR\": psnr, \"SSIM\": ssim},\n",
    "    max_epochs=epochs,\n",
    "    check_val_every_epochs=check_val_every_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./checkpoint_Unet_supervised.pth\"\n",
    "print_training_curves(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
